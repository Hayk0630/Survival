{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067df5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8ea49",
   "metadata": {},
   "source": [
    "reading csv dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c2179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Survival_dataset.csv')\n",
    "y = df['In-hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6f59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\n",
    "            'Length_of_stay',\n",
    "            'Survival',\n",
    "            'SAPS-I',\n",
    "            'SOFA',\n",
    "            'In-hospital_death'\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495a99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(\n",
    "            imputer.fit_transform(df),\n",
    "            columns=df.columns\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12477e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordid</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>CCU</th>\n",
       "      <th>CSRU</th>\n",
       "      <th>SICU</th>\n",
       "      <th>DiasABP_first</th>\n",
       "      <th>GCS_first</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP_last</th>\n",
       "      <th>TroponinI_last</th>\n",
       "      <th>TroponinT_last</th>\n",
       "      <th>WBC_last</th>\n",
       "      <th>Weight_last</th>\n",
       "      <th>pH_last</th>\n",
       "      <th>MechVentStartTime</th>\n",
       "      <th>MechVentDuration</th>\n",
       "      <th>MechVentLast8Hour</th>\n",
       "      <th>UrineOutputSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>81.474832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.370637</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.461871</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>9.4</td>\n",
       "      <td>85.037344</td>\n",
       "      <td>7.398693</td>\n",
       "      <td>285.17675</td>\n",
       "      <td>1912.00514</td>\n",
       "      <td>0.620799</td>\n",
       "      <td>12.314749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132540.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.300000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>13.3</td>\n",
       "      <td>81.600000</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>71.00000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132541.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>6.2</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.470000</td>\n",
       "      <td>617.00000</td>\n",
       "      <td>2160.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132543.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.300000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.370637</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.461871</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>7.9</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.398693</td>\n",
       "      <td>285.17675</td>\n",
       "      <td>1912.00514</td>\n",
       "      <td>0.620799</td>\n",
       "      <td>12.314749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132545.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>81.474832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.370637</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.461871</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>4.8</td>\n",
       "      <td>85.037344</td>\n",
       "      <td>7.398693</td>\n",
       "      <td>285.17675</td>\n",
       "      <td>1912.00514</td>\n",
       "      <td>0.620799</td>\n",
       "      <td>12.314749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>142665.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>17.5</td>\n",
       "      <td>85.037344</td>\n",
       "      <td>7.390000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>1200.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>142667.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>166.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.370637</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.461871</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>3.0</td>\n",
       "      <td>166.400000</td>\n",
       "      <td>7.398693</td>\n",
       "      <td>285.17675</td>\n",
       "      <td>1912.00514</td>\n",
       "      <td>0.620799</td>\n",
       "      <td>12.314749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>142670.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>10.6</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>2580.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>142671.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.985856</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>11.5</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>2585.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>142673.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.500000</td>\n",
       "      <td>70.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>6.466341</td>\n",
       "      <td>1.002283</td>\n",
       "      <td>11.0</td>\n",
       "      <td>87.300000</td>\n",
       "      <td>7.310000</td>\n",
       "      <td>216.00000</td>\n",
       "      <td>2295.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordid   Age  Gender      Height      Weight  CCU  CSRU  SICU  \\\n",
       "0     132539.0  54.0     0.0  171.985856   81.474832  0.0   0.0   1.0   \n",
       "1     132540.0  76.0     1.0  175.300000   76.000000  0.0   1.0   0.0   \n",
       "2     132541.0  44.0     0.0  171.985856   56.700000  0.0   0.0   0.0   \n",
       "3     132543.0  68.0     1.0  180.300000   84.600000  0.0   0.0   0.0   \n",
       "4     132545.0  88.0     0.0  171.985856   81.474832  0.0   0.0   0.0   \n",
       "...        ...   ...     ...         ...         ...  ...   ...   ...   \n",
       "3995  142665.0  70.0     0.0  171.985856   87.000000  0.0   0.0   1.0   \n",
       "3996  142667.0  25.0     1.0  171.985856  166.400000  0.0   0.0   0.0   \n",
       "3997  142670.0  44.0     1.0  171.985856  109.000000  0.0   0.0   0.0   \n",
       "3998  142671.0  37.0     1.0  171.985856   87.400000  0.0   0.0   0.0   \n",
       "3999  142673.0  78.0     0.0  157.500000   70.700000  0.0   0.0   1.0   \n",
       "\n",
       "      DiasABP_first  GCS_first  ...  SysABP_last  TroponinI_last  \\\n",
       "0         62.370637       15.0  ...   122.461871        6.466341   \n",
       "1         67.000000        3.0  ...   103.000000        6.466341   \n",
       "2         81.000000        7.0  ...   126.000000        6.466341   \n",
       "3         62.370637       15.0  ...   122.461871        6.466341   \n",
       "4         62.370637       15.0  ...   122.461871        6.466341   \n",
       "...             ...        ...  ...          ...             ...   \n",
       "3995      50.000000        3.0  ...   152.000000        6.466341   \n",
       "3996      62.370637       15.0  ...   122.461871        6.466341   \n",
       "3997      67.000000        8.0  ...   113.000000        6.466341   \n",
       "3998      88.000000        6.0  ...   145.000000        6.466341   \n",
       "3999      62.000000        3.0  ...   129.000000        6.466341   \n",
       "\n",
       "      TroponinT_last  WBC_last  Weight_last   pH_last  MechVentStartTime  \\\n",
       "0           1.002283       9.4    85.037344  7.398693          285.17675   \n",
       "1           1.002283      13.3    81.600000  7.370000           71.00000   \n",
       "2           1.002283       6.2    56.700000  7.470000          617.00000   \n",
       "3           1.002283       7.9    84.600000  7.398693          285.17675   \n",
       "4           1.002283       4.8    85.037344  7.398693          285.17675   \n",
       "...              ...       ...          ...       ...                ...   \n",
       "3995        1.002283      17.5    85.037344  7.390000           23.00000   \n",
       "3996        1.002283       3.0   166.400000  7.398693          285.17675   \n",
       "3997        1.002283      10.6   109.000000  7.410000           80.00000   \n",
       "3998        1.002283      11.5    87.400000  7.340000           82.00000   \n",
       "3999        1.002283      11.0    87.300000  7.310000          216.00000   \n",
       "\n",
       "      MechVentDuration  MechVentLast8Hour  UrineOutputSum  \n",
       "0           1912.00514           0.620799       12.314749  \n",
       "1            360.00000           0.000000        5.000000  \n",
       "2           2160.00000           1.000000       14.000000  \n",
       "3           1912.00514           0.620799       12.314749  \n",
       "4           1912.00514           0.620799       12.314749  \n",
       "...                ...                ...             ...  \n",
       "3995        1200.00000           0.000000        6.000000  \n",
       "3996        1912.00514           0.620799       12.314749  \n",
       "3997        2580.00000           1.000000       15.000000  \n",
       "3998        2585.00000           1.000000       15.000000  \n",
       "3999        2295.00000           1.000000       19.000000  \n",
       "\n",
       "[4000 rows x 115 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7c6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70efaba5",
   "metadata": {},
   "source": [
    "## In-hospital mortality prediction (weighted recall/precision)\n",
    "\n",
    "This section is a clean, portfolio-ready workflow:\n",
    "- prepare data\n",
    "- split into train/validation/test\n",
    "- train Logistic Regression, Random Forest, and Boosting\n",
    "- tune decision thresholds\n",
    "- compare final test performance with weighted objective (80% recall, 20% precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d25307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75eea66",
   "metadata": {},
   "source": [
    "### 1) Load dataset and define features/target\n",
    "\n",
    "We keep the same target (`In-hospital_death`) and drop columns that should not be used as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80831d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4000, 120)\n",
      "Feature matrix shape: (4000, 115)\n",
      "Positive class rate: 0.1385\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLUMN = 'In-hospital_death'\n",
    "DROP_COLUMNS = [\n",
    "    'Length_of_stay',\n",
    "    'Survival',\n",
    "    'SAPS-I',\n",
    "    'SOFA',\n",
    "    TARGET_COLUMN,\n",
    "]\n",
    "\n",
    "df = pd.read_csv('Survival_dataset.csv')\n",
    "y = df[TARGET_COLUMN].astype(int)\n",
    "X = df.drop(DROP_COLUMNS, axis=1)\n",
    "\n",
    "print('Dataset shape:', df.shape)\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Positive class rate:', round(y.mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583e3ec",
   "metadata": {},
   "source": [
    "### 2) Split into train/validation/test\n",
    "\n",
    "We use stratified splits to preserve class imbalance in all subsets:\n",
    "- 60% train\n",
    "- 20% validation\n",
    "- 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad6ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2800\n",
      "Validation size: 900\n",
      "Test size: 300\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y_temp,\n",
    ")\n",
    "\n",
    "print('Train size:', len(X_train))\n",
    "print('Validation size:', len(X_val))\n",
    "print('Test size:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d64d0d",
   "metadata": {},
   "source": [
    "### 3) Define weighted recall/precision evaluation\n",
    "\n",
    "We tune thresholds with a weighted objective:\n",
    "- 80% importance: recall\n",
    "- 20% importance: precision\n",
    "\n",
    "Score used for selection: `0.8 * recall + 0.2 * precision`.\n",
    "Tie-breakers: recall, F1, then lower threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee236aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average='binary',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_thresholds(\n",
    "    model,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    thresholds,\n",
    "    recall_weight=0.8,\n",
    "    precision_weight=0.2,\n",
    "):\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    rows = []\n",
    "\n",
    "    for thr in thresholds:\n",
    "        y_pred = (val_proba >= thr).astype(int)\n",
    "        metrics = compute_metrics(y_val, y_pred)\n",
    "        weighted_score = (\n",
    "            recall_weight * metrics['recall']\n",
    "            + precision_weight * metrics['precision']\n",
    "        )\n",
    "        rows.append(\n",
    "            {\n",
    "                'threshold': float(thr),\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'f1': metrics['f1'],\n",
    "                'weighted_score': weighted_score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    threshold_df = pd.DataFrame(rows).sort_values(\n",
    "        by=['weighted_score', 'recall', 'f1', 'threshold'],\n",
    "        ascending=[False, False, False, True],\n",
    "    )\n",
    "    best = threshold_df.iloc[0].to_dict()\n",
    "    return threshold_df, best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbdc02c",
   "metadata": {},
   "source": [
    "### 4) Train models, tune parameters, and compare on test\n",
    "\n",
    "- Logistic Regression: fit once, then tune threshold with weighted score.\n",
    "- Random Forest: test multiple hyperparameter sets, tune threshold for each.\n",
    "- Boosting: test multiple hyperparameter sets, tune threshold for each.\n",
    "- Selection objective: `0.8 * recall + 0.2 * precision` (validation).\n",
    "- Final table is ranked by weighted test score, then recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "099bc53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LogisticRegression - validation metrics by threshold\n",
      "======================================================================\n",
      " threshold  precision  recall       f1  weighted_score\n",
      "      0.10   0.195759   0.960 0.325203        0.807152\n",
      "      0.15   0.214022   0.928 0.347826        0.785204\n",
      "      0.20   0.236287   0.896 0.373957        0.764057\n",
      "      0.25   0.250000   0.880 0.389381        0.754000\n",
      "      0.30   0.259901   0.840 0.396975        0.723980\n",
      "      0.35   0.282192   0.824 0.420408        0.715638\n",
      "      0.40   0.280967   0.744 0.407895        0.651393\n",
      "      0.45   0.296667   0.712 0.418824        0.628933\n",
      "      0.50   0.319703   0.688 0.436548        0.614341\n",
      "      0.55   0.346154   0.648 0.451253        0.587631\n",
      "      0.60   0.367150   0.608 0.457831        0.559830\n",
      "      0.65   0.387978   0.568 0.461039        0.531996\n",
      "      0.70   0.412500   0.528 0.463158        0.504900\n",
      "      0.75   0.411348   0.464 0.436090        0.453470\n",
      "      0.80   0.438017   0.424 0.430894        0.426803\n",
      "      0.85   0.441558   0.272 0.336634        0.305912\n",
      "      0.90   0.437500   0.168 0.242775        0.221900\n",
      "\n",
      "======================================================================\n",
      "RandomForest - parameter search summary (sorted by weighted validation score)\n",
      "======================================================================\n",
      "                                              params  selected_threshold  val_weighted_score  val_recall  val_precision   val_f1  test_weighted_score  test_recall  test_precision  test_f1\n",
      "   n_estimators=600, max_depth=8, min_samples_leaf=5                 0.1            0.832680       1.000       0.163399 0.280899             0.832157     1.000000        0.160784 0.277027\n",
      "  n_estimators=400, max_depth=10, min_samples_leaf=3                 0.1            0.824192       0.984       0.184962 0.311392             0.836444     1.000000        0.182222 0.308271\n",
      "n_estimators=200, max_depth=None, min_samples_leaf=1                 0.1            0.811600       0.952       0.250000 0.396007             0.788089     0.926829        0.233129 0.372549\n",
      "n_estimators=400, max_depth=None, min_samples_leaf=1                 0.1            0.806062       0.944       0.254310 0.400679             0.788668     0.926829        0.236025 0.376238\n",
      "  n_estimators=400, max_depth=12, min_samples_leaf=1                 0.1            0.805511       0.952       0.219557 0.356822             0.822373     0.975610        0.209424 0.344828\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Best RandomForest threshold table:\n",
      "n_estimators=600, max_depth=8, min_samples_leaf=5\n",
      " threshold  precision  recall       f1  weighted_score\n",
      "      0.10   0.163399   1.000 0.280899        0.832680\n",
      "      0.15   0.185976   0.976 0.312420        0.817995\n",
      "      0.20   0.219331   0.944 0.355958        0.799066\n",
      "      0.25   0.256071   0.928 0.401384        0.793614\n",
      "      0.30   0.300000   0.864 0.445361        0.751200\n",
      "      0.35   0.338129   0.752 0.466501        0.669226\n",
      "      0.40   0.398148   0.688 0.504399        0.630030\n",
      "      0.45   0.460526   0.560 0.505415        0.540105\n",
      "      0.50   0.500000   0.416 0.454148        0.432800\n",
      "      0.55   0.578947   0.264 0.362637        0.326989\n",
      "      0.60   0.657895   0.200 0.306748        0.291579\n",
      "      0.70   1.000000   0.048 0.091603        0.238400\n",
      "      0.75   1.000000   0.016 0.031496        0.212800\n",
      "      0.65   0.750000   0.072 0.131387        0.207600\n",
      "      0.80   0.000000   0.000 0.000000        0.000000\n",
      "      0.85   0.000000   0.000 0.000000        0.000000\n",
      "      0.90   0.000000   0.000 0.000000        0.000000\n",
      "\n",
      "======================================================================\n",
      "GradientBoosting - parameter search summary (sorted by weighted validation score)\n",
      "======================================================================\n",
      "                                                               params  selected_threshold  val_weighted_score  val_recall  val_precision   val_f1  test_weighted_score  test_recall  test_precision  test_f1\n",
      " n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_leaf=1                 0.1            0.825638       0.984       0.192188 0.321569             0.837443          1.0        0.187215 0.315385\n",
      "n_estimators=300, learning_rate=0.03, max_depth=2, min_samples_leaf=3                 0.1            0.825192       0.992       0.157962 0.272527             0.830370          1.0        0.151852 0.263666\n",
      "n_estimators=150, learning_rate=0.08, max_depth=2, min_samples_leaf=5                 0.1            0.820624       0.984       0.167120 0.285714             0.832411          1.0        0.162055 0.278912\n",
      "n_estimators=200, learning_rate=0.05, max_depth=3, min_samples_leaf=2                 0.1            0.818166       0.976       0.186830 0.313625             0.836771          1.0        0.183857 0.310606\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Best GradientBoosting threshold table:\n",
      "n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_leaf=1\n",
      " threshold  precision  recall       f1  weighted_score\n",
      "      0.10   0.192188   0.984 0.321569        0.825638\n",
      "      0.15   0.222628   0.976 0.362556        0.825326\n",
      "      0.20   0.247401   0.952 0.392739        0.811080\n",
      "      0.25   0.271663   0.928 0.420290        0.796733\n",
      "      0.30   0.298667   0.896 0.448000        0.776533\n",
      "      0.35   0.330189   0.840 0.474041        0.738038\n",
      "      0.40   0.345196   0.776 0.477833        0.689839\n",
      "      0.45   0.371795   0.696 0.484680        0.631159\n",
      "      0.50   0.411168   0.648 0.503106        0.600634\n",
      "      0.55   0.434524   0.584 0.498294        0.554105\n",
      "      0.60   0.500000   0.536 0.517375        0.528800\n",
      "      0.65   0.528846   0.440 0.480349        0.457769\n",
      "      0.70   0.567901   0.368 0.446602        0.407980\n",
      "      0.75   0.611111   0.264 0.368715        0.333422\n",
      "      0.80   0.710526   0.216 0.331288        0.314905\n",
      "      0.85   0.809524   0.136 0.232877        0.270705\n",
      "      0.90   0.571429   0.032 0.060606        0.139886\n",
      "\n",
      "######################################################################\n",
      "FINAL COMPARISON (Logistic vs RandomForest vs Boosting)\n",
      "######################################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>selected_threshold</th>\n",
       "      <th>val_weighted_score</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>test_weighted_score</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>n_estimators=100, learning_rate=0.1, max_depth...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.825638</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.837443</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.187215</td>\n",
       "      <td>0.315385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>n_estimators=600, max_depth=8, min_samples_leaf=5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.832680</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.832157</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.277027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>default_balanced_liblinear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.807152</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.195759</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.816687</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.180995</td>\n",
       "      <td>0.305344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                             params  \\\n",
       "2    GradientBoosting  n_estimators=100, learning_rate=0.1, max_depth...   \n",
       "1        RandomForest  n_estimators=600, max_depth=8, min_samples_leaf=5   \n",
       "0  LogisticRegression                         default_balanced_liblinear   \n",
       "\n",
       "   selected_threshold  val_weighted_score  val_recall  val_precision  \\\n",
       "2                 0.1            0.825638       0.984       0.192188   \n",
       "1                 0.1            0.832680       1.000       0.163399   \n",
       "0                 0.1            0.807152       0.960       0.195759   \n",
       "\n",
       "     val_f1  test_weighted_score  test_recall  test_precision   test_f1  \n",
       "2  0.321569             0.837443      1.00000        0.187215  0.315385  \n",
       "1  0.280899             0.832157      1.00000        0.160784  0.277027  \n",
       "0  0.325203             0.816687      0.97561        0.180995  0.305344  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECALL_WEIGHT = 0.8\n",
    "PRECISION_WEIGHT = 0.2\n",
    "\n",
    "logistic_model = Pipeline(\n",
    "    [\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        (\n",
    "            'model',\n",
    "            LogisticRegression(\n",
    "                class_weight='balanced',\n",
    "                solver='liblinear',\n",
    "                max_iter=5000,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_param_grid = [\n",
    "    {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1},\n",
    "    {'n_estimators': 400, 'max_depth': None, 'min_samples_leaf': 1},\n",
    "    {'n_estimators': 400, 'max_depth': 12, 'min_samples_leaf': 1},\n",
    "    {'n_estimators': 400, 'max_depth': 10, 'min_samples_leaf': 3},\n",
    "    {'n_estimators': 600, 'max_depth': 8, 'min_samples_leaf': 5},\n",
    "]\n",
    "\n",
    "gb_param_grid = [\n",
    "    {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 1},\n",
    "    {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 3, 'min_samples_leaf': 2},\n",
    "    {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 2, 'min_samples_leaf': 3},\n",
    "    {'n_estimators': 150, 'learning_rate': 0.08, 'max_depth': 2, 'min_samples_leaf': 5},\n",
    "]\n",
    "\n",
    "thresholds = np.arange(0.10, 0.95, 0.05)\n",
    "summary_rows = []\n",
    "\n",
    "# 1) Logistic Regression\n",
    "logistic_model.fit(X_train, y_train)\n",
    "log_val_table, log_best = evaluate_thresholds(\n",
    "    logistic_model,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    thresholds,\n",
    "    recall_weight=RECALL_WEIGHT,\n",
    "    precision_weight=PRECISION_WEIGHT,\n",
    ")\n",
    "log_best_threshold = log_best['threshold']\n",
    "\n",
    "log_test_proba = logistic_model.predict_proba(X_test)[:, 1]\n",
    "log_y_test_pred = (log_test_proba >= log_best_threshold).astype(int)\n",
    "log_test_metrics = compute_metrics(y_test, log_y_test_pred)\n",
    "log_test_weighted_score = (\n",
    "    RECALL_WEIGHT * log_test_metrics['recall']\n",
    "    + PRECISION_WEIGHT * log_test_metrics['precision']\n",
    ")\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('LogisticRegression - validation metrics by threshold')\n",
    "print('=' * 70)\n",
    "print(log_val_table.to_string(index=False))\n",
    "\n",
    "summary_rows.append(\n",
    "    {\n",
    "        'model': 'LogisticRegression',\n",
    "        'params': 'default_balanced_liblinear',\n",
    "        'selected_threshold': log_best_threshold,\n",
    "        'val_weighted_score': log_best['weighted_score'],\n",
    "        'val_recall': log_best['recall'],\n",
    "        'val_precision': log_best['precision'],\n",
    "        'val_f1': log_best['f1'],\n",
    "        'test_weighted_score': log_test_weighted_score,\n",
    "        'test_recall': log_test_metrics['recall'],\n",
    "        'test_precision': log_test_metrics['precision'],\n",
    "        'test_f1': log_test_metrics['f1'],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2) Random Forest parameter search + threshold tuning\n",
    "rf_runs = []\n",
    "for rf_params in rf_param_grid:\n",
    "    rf_model = Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=rf_params['n_estimators'],\n",
    "                    max_depth=rf_params['max_depth'],\n",
    "                    min_samples_leaf=rf_params['min_samples_leaf'],\n",
    "                    class_weight='balanced',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_val_table, rf_best = evaluate_thresholds(\n",
    "        rf_model,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        thresholds,\n",
    "        recall_weight=RECALL_WEIGHT,\n",
    "        precision_weight=PRECISION_WEIGHT,\n",
    "    )\n",
    "\n",
    "    rf_best_threshold = rf_best['threshold']\n",
    "    rf_test_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    rf_y_test_pred = (rf_test_proba >= rf_best_threshold).astype(int)\n",
    "    rf_test_metrics = compute_metrics(y_test, rf_y_test_pred)\n",
    "    rf_test_weighted_score = (\n",
    "        RECALL_WEIGHT * rf_test_metrics['recall']\n",
    "        + PRECISION_WEIGHT * rf_test_metrics['precision']\n",
    "    )\n",
    "\n",
    "    params_label = (\n",
    "        f\"n_estimators={rf_params['n_estimators']}, \"\n",
    "        f\"max_depth={rf_params['max_depth']}, \"\n",
    "        f\"min_samples_leaf={rf_params['min_samples_leaf']}\"\n",
    "    )\n",
    "\n",
    "    rf_runs.append(\n",
    "        {\n",
    "            'model': 'RandomForest',\n",
    "            'params': params_label,\n",
    "            'selected_threshold': rf_best_threshold,\n",
    "            'val_weighted_score': rf_best['weighted_score'],\n",
    "            'val_recall': rf_best['recall'],\n",
    "            'val_precision': rf_best['precision'],\n",
    "            'val_f1': rf_best['f1'],\n",
    "            'test_weighted_score': rf_test_weighted_score,\n",
    "            'test_recall': rf_test_metrics['recall'],\n",
    "            'test_precision': rf_test_metrics['precision'],\n",
    "            'test_f1': rf_test_metrics['f1'],\n",
    "            'val_table': rf_val_table,\n",
    "        }\n",
    "    )\n",
    "\n",
    "rf_results_df = pd.DataFrame(rf_runs).sort_values(\n",
    "    by=['val_weighted_score', 'val_recall', 'val_precision', 'val_f1'],\n",
    "    ascending=False,\n",
    ")\n",
    "\n",
    "best_rf = rf_runs[rf_results_df.index[0]]\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('RandomForest - parameter search summary (sorted by weighted validation score)')\n",
    "print('=' * 70)\n",
    "print(\n",
    "    rf_results_df[\n",
    "        [\n",
    "            'params',\n",
    "            'selected_threshold',\n",
    "            'val_weighted_score',\n",
    "            'val_recall',\n",
    "            'val_precision',\n",
    "            'val_f1',\n",
    "            'test_weighted_score',\n",
    "            'test_recall',\n",
    "            'test_precision',\n",
    "            'test_f1',\n",
    "        ]\n",
    "    ].to_string(index=False)\n",
    ")\n",
    "\n",
    "print('\\n' + '-' * 70)\n",
    "print('Best RandomForest threshold table:')\n",
    "print(best_rf['params'])\n",
    "print(best_rf['val_table'].to_string(index=False))\n",
    "\n",
    "summary_rows.append(\n",
    "    {\n",
    "        'model': best_rf['model'],\n",
    "        'params': best_rf['params'],\n",
    "        'selected_threshold': best_rf['selected_threshold'],\n",
    "        'val_weighted_score': best_rf['val_weighted_score'],\n",
    "        'val_recall': best_rf['val_recall'],\n",
    "        'val_precision': best_rf['val_precision'],\n",
    "        'val_f1': best_rf['val_f1'],\n",
    "        'test_weighted_score': best_rf['test_weighted_score'],\n",
    "        'test_recall': best_rf['test_recall'],\n",
    "        'test_precision': best_rf['test_precision'],\n",
    "        'test_f1': best_rf['test_f1'],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3) Gradient Boosting parameter search + threshold tuning\n",
    "gb_runs = []\n",
    "train_sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "for gb_params in gb_param_grid:\n",
    "    gb_model = Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                GradientBoostingClassifier(\n",
    "                    n_estimators=gb_params['n_estimators'],\n",
    "                    learning_rate=gb_params['learning_rate'],\n",
    "                    max_depth=gb_params['max_depth'],\n",
    "                    min_samples_leaf=gb_params['min_samples_leaf'],\n",
    "                    random_state=42,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gb_model.fit(X_train, y_train, model__sample_weight=train_sample_weight)\n",
    "    gb_val_table, gb_best = evaluate_thresholds(\n",
    "        gb_model,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        thresholds,\n",
    "        recall_weight=RECALL_WEIGHT,\n",
    "        precision_weight=PRECISION_WEIGHT,\n",
    "    )\n",
    "\n",
    "    gb_best_threshold = gb_best['threshold']\n",
    "    gb_test_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "    gb_y_test_pred = (gb_test_proba >= gb_best_threshold).astype(int)\n",
    "    gb_test_metrics = compute_metrics(y_test, gb_y_test_pred)\n",
    "    gb_test_weighted_score = (\n",
    "        RECALL_WEIGHT * gb_test_metrics['recall']\n",
    "        + PRECISION_WEIGHT * gb_test_metrics['precision']\n",
    "    )\n",
    "\n",
    "    params_label = (\n",
    "        f\"n_estimators={gb_params['n_estimators']}, \"\n",
    "        f\"learning_rate={gb_params['learning_rate']}, \"\n",
    "        f\"max_depth={gb_params['max_depth']}, \"\n",
    "        f\"min_samples_leaf={gb_params['min_samples_leaf']}\"\n",
    "    )\n",
    "\n",
    "    gb_runs.append(\n",
    "        {\n",
    "            'model': 'GradientBoosting',\n",
    "            'params': params_label,\n",
    "            'selected_threshold': gb_best_threshold,\n",
    "            'val_weighted_score': gb_best['weighted_score'],\n",
    "            'val_recall': gb_best['recall'],\n",
    "            'val_precision': gb_best['precision'],\n",
    "            'val_f1': gb_best['f1'],\n",
    "            'test_weighted_score': gb_test_weighted_score,\n",
    "            'test_recall': gb_test_metrics['recall'],\n",
    "            'test_precision': gb_test_metrics['precision'],\n",
    "            'test_f1': gb_test_metrics['f1'],\n",
    "            'val_table': gb_val_table,\n",
    "        }\n",
    "    )\n",
    "\n",
    "gb_results_df = pd.DataFrame(gb_runs).sort_values(\n",
    "    by=['val_weighted_score', 'val_recall', 'val_precision', 'val_f1'],\n",
    "    ascending=False,\n",
    ")\n",
    "\n",
    "best_gb = gb_runs[gb_results_df.index[0]]\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('GradientBoosting - parameter search summary (sorted by weighted validation score)')\n",
    "print('=' * 70)\n",
    "print(\n",
    "    gb_results_df[\n",
    "        [\n",
    "            'params',\n",
    "            'selected_threshold',\n",
    "            'val_weighted_score',\n",
    "            'val_recall',\n",
    "            'val_precision',\n",
    "            'val_f1',\n",
    "            'test_weighted_score',\n",
    "            'test_recall',\n",
    "            'test_precision',\n",
    "            'test_f1',\n",
    "        ]\n",
    "    ].to_string(index=False)\n",
    ")\n",
    "\n",
    "print('\\n' + '-' * 70)\n",
    "print('Best GradientBoosting threshold table:')\n",
    "print(best_gb['params'])\n",
    "print(best_gb['val_table'].to_string(index=False))\n",
    "\n",
    "summary_rows.append(\n",
    "    {\n",
    "        'model': best_gb['model'],\n",
    "        'params': best_gb['params'],\n",
    "        'selected_threshold': best_gb['selected_threshold'],\n",
    "        'val_weighted_score': best_gb['val_weighted_score'],\n",
    "        'val_recall': best_gb['val_recall'],\n",
    "        'val_precision': best_gb['val_precision'],\n",
    "        'val_f1': best_gb['val_f1'],\n",
    "        'test_weighted_score': best_gb['test_weighted_score'],\n",
    "        'test_recall': best_gb['test_recall'],\n",
    "        'test_precision': best_gb['test_precision'],\n",
    "        'test_f1': best_gb['test_f1'],\n",
    "    }\n",
    ")\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\n",
    "    by=['test_weighted_score', 'test_recall', 'test_precision'],\n",
    "    ascending=False,\n",
    ")\n",
    "\n",
    "print('\\n' + '#' * 70)\n",
    "print('FINAL COMPARISON (Logistic vs RandomForest vs Boosting)')\n",
    "print('#' * 70)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d9ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70daac33",
   "metadata": {},
   "source": [
    "### 5) Practical precision boost: choose threshold with a minimum precision\n",
    "\n",
    "If precision around 20% is too low, force a minimum precision on validation (for example 30%).\n",
    "Then pick the threshold with the best weighted score among those valid thresholds.\n",
    "\n",
    "This usually increases precision and decreases recall slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a76e715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression constrained choice\n",
      "Threshold: 0.5\n",
      "Validation precision/recall: 0.3197 0.688\n",
      "Test precision/recall: 0.303 0.7317\n",
      "Test weighted score: 0.646\n",
      "\n",
      "RandomForest constrained choice\n",
      "Threshold: 0.3\n",
      "Validation precision/recall: 0.3 0.864\n",
      "Test precision/recall: 0.296 0.9024\n",
      "Test weighted score: 0.7812\n",
      "\n",
      "Tip: increase MIN_VALIDATION_PRECISION to push precision higher.\n"
     ]
    }
   ],
   "source": [
    "MIN_VALIDATION_PRECISION = 0.30\n",
    "\n",
    "def choose_threshold_with_min_precision(val_table, min_precision=0.30):\n",
    "    filtered = val_table[val_table['precision'] >= min_precision].copy()\n",
    "\n",
    "    if filtered.empty:\n",
    "        return None, filtered\n",
    "\n",
    "    filtered = filtered.sort_values(\n",
    "        by=['weighted_score', 'recall', 'f1', 'threshold'],\n",
    "        ascending=[False, False, False, True],\n",
    "    )\n",
    "    return filtered.iloc[0].to_dict(), filtered\n",
    "\n",
    "log_constrained_best, log_valid_thresholds = choose_threshold_with_min_precision(\n",
    "    log_val_table,\n",
    "    min_precision=MIN_VALIDATION_PRECISION,\n",
    ")\n",
    "\n",
    "if log_constrained_best is None:\n",
    "    print('No LogisticRegression threshold satisfies the minimum precision.')\n",
    "else:\n",
    "    log_thr = log_constrained_best['threshold']\n",
    "    log_pred = (log_test_proba >= log_thr).astype(int)\n",
    "    log_m = compute_metrics(y_test, log_pred)\n",
    "    log_ws = RECALL_WEIGHT * log_m['recall'] + PRECISION_WEIGHT * log_m['precision']\n",
    "\n",
    "    print('LogisticRegression constrained choice')\n",
    "    print('Threshold:', round(log_thr, 2))\n",
    "    print('Validation precision/recall:', round(log_constrained_best['precision'], 4), round(log_constrained_best['recall'], 4))\n",
    "    print('Test precision/recall:', round(log_m['precision'], 4), round(log_m['recall'], 4))\n",
    "    print('Test weighted score:', round(log_ws, 4))\n",
    "\n",
    "rf_best_table = best_rf['val_table']\n",
    "rf_constrained_best, rf_valid_thresholds = choose_threshold_with_min_precision(\n",
    "    rf_best_table,\n",
    "    min_precision=MIN_VALIDATION_PRECISION,\n",
    ")\n",
    "\n",
    "if rf_constrained_best is None:\n",
    "    print('\\nNo RandomForest threshold satisfies the minimum precision.')\n",
    "else:\n",
    "    rf_thr = rf_constrained_best['threshold']\n",
    "    rf_pred = (rf_test_proba >= rf_thr).astype(int)\n",
    "    rf_m = compute_metrics(y_test, rf_pred)\n",
    "    rf_ws = RECALL_WEIGHT * rf_m['recall'] + PRECISION_WEIGHT * rf_m['precision']\n",
    "\n",
    "    print('\\nRandomForest constrained choice')\n",
    "    print('Threshold:', round(rf_thr, 2))\n",
    "    print('Validation precision/recall:', round(rf_constrained_best['precision'], 4), round(rf_constrained_best['recall'], 4))\n",
    "    print('Test precision/recall:', round(rf_m['precision'], 4), round(rf_m['recall'], 4))\n",
    "    print('Test weighted score:', round(rf_ws, 4))\n",
    "\n",
    "print('\\nTip: increase MIN_VALIDATION_PRECISION to push precision higher.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9df4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff382377",
   "metadata": {},
   "source": [
    "### 6) Feasibility check for a strict operating point (Precision â‰¥ 0.80, Recall â‰¥ 0.90)\n",
    "\n",
    "This cell tests several strong model candidates and searches thresholds.\n",
    "Now includes:\n",
    "- Logistic Regression\n",
    "- Random Forest / Extra Trees / Gradient Boosting variants\n",
    "- XGBoost (if installed)\n",
    "- LightGBM (if installed)\n",
    "\n",
    "It reports:\n",
    "- whether **both** targets can be reached together,\n",
    "- best precision achievable while keeping recall â‰¥ 0.90,\n",
    "- best recall achievable while keeping precision â‰¥ 0.80.\n",
    "\n",
    "If no model meets both, we likely need better features, more data, or a different problem framing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e6c4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost available: True\n",
      "LightGBM available: True\n",
      "Can we hit Precision >= 0.80 and Recall >= 0.90 on validation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\Desktop\\programming\\projects\\Survival\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feasible_precision&gt;=0.80_recall&gt;=0.90</th>\n",
       "      <th>best_precision_when_recall&gt;=0.90</th>\n",
       "      <th>best_recall_when_precision&gt;=0.80</th>\n",
       "      <th>threshold_if_both_feasible</th>\n",
       "      <th>precision_if_both_feasible</th>\n",
       "      <th>recall_if_both_feasible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting_weighted</td>\n",
       "      <td>False</td>\n",
       "      <td>0.294271</td>\n",
       "      <td>0.104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_stronger</td>\n",
       "      <td>False</td>\n",
       "      <td>0.288608</td>\n",
       "      <td>0.072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>False</td>\n",
       "      <td>0.279012</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>False</td>\n",
       "      <td>0.275610</td>\n",
       "      <td>0.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273608</td>\n",
       "      <td>0.128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>False</td>\n",
       "      <td>0.252232</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>False</td>\n",
       "      <td>0.232990</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  feasible_precision>=0.80_recall>=0.90  \\\n",
       "4  GradientBoosting_weighted                                  False   \n",
       "1      RandomForest_stronger                                  False   \n",
       "3       HistGradientBoosting                                  False   \n",
       "5                    XGBoost                                  False   \n",
       "6                   LightGBM                                  False   \n",
       "2                 ExtraTrees                                  False   \n",
       "0         LogisticRegression                                  False   \n",
       "\n",
       "   best_precision_when_recall>=0.90  best_recall_when_precision>=0.80  \\\n",
       "4                          0.294271                             0.104   \n",
       "1                          0.288608                             0.072   \n",
       "3                          0.279012                             0.016   \n",
       "5                          0.275610                             0.080   \n",
       "6                          0.273608                             0.128   \n",
       "2                          0.252232                             0.040   \n",
       "0                          0.232990                             0.032   \n",
       "\n",
       "   threshold_if_both_feasible  precision_if_both_feasible  \\\n",
       "4                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "3                         NaN                         NaN   \n",
       "5                         NaN                         NaN   \n",
       "6                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "0                         NaN                         NaN   \n",
       "\n",
       "   recall_if_both_feasible  \n",
       "4                      NaN  \n",
       "1                      NaN  \n",
       "3                      NaN  \n",
       "5                      NaN  \n",
       "6                      NaN  \n",
       "2                      NaN  \n",
       "0                      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "TARGET_PRECISION = 0.80\n",
    "TARGET_RECALL = 0.90\n",
    "\n",
    "# Optional boosting libraries\n",
    "xgb_available = True\n",
    "lgbm_available = True\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    xgb_available = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except ImportError:\n",
    "    lgbm_available = False\n",
    "\n",
    "# Class imbalance ratio for external boosting libraries\n",
    "neg_count = int((y_train == 0).sum())\n",
    "pos_count = int((y_train == 1).sum())\n",
    "scale_pos_weight = neg_count / max(pos_count, 1)\n",
    "\n",
    "candidate_models = {\n",
    "    'LogisticRegression': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('model', LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=5000, random_state=42)),\n",
    "        ]\n",
    "    ),\n",
    "    'RandomForest_stronger': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('model', RandomForestClassifier(n_estimators=500, max_depth=8, min_samples_leaf=5, class_weight='balanced', random_state=42, n_jobs=-1)),\n",
    "        ]\n",
    "    ),\n",
    "    'ExtraTrees': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('model', ExtraTreesClassifier(n_estimators=500, max_depth=10, min_samples_leaf=3, class_weight='balanced', random_state=42, n_jobs=-1)),\n",
    "        ]\n",
    "    ),\n",
    "    'HistGradientBoosting': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('model', HistGradientBoostingClassifier(max_iter=200, learning_rate=0.05, max_depth=6, min_samples_leaf=20, random_state=42)),\n",
    "        ]\n",
    "    ),\n",
    "    'GradientBoosting_weighted': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('model', GradientBoostingClassifier(n_estimators=150, learning_rate=0.05, max_depth=2, min_samples_leaf=3, random_state=42)),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "if xgb_available:\n",
    "    candidate_models['XGBoost'] = Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                XGBClassifier(\n",
    "                    n_estimators=300,\n",
    "                    learning_rate=0.05,\n",
    "                    max_depth=4,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.8,\n",
    "                    reg_lambda=2.0,\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    objective='binary:logistic',\n",
    "                    eval_metric='logloss',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "if lgbm_available:\n",
    "    candidate_models['LightGBM'] = Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                LGBMClassifier(\n",
    "                    n_estimators=300,\n",
    "                    learning_rate=0.05,\n",
    "                    num_leaves=31,\n",
    "                    max_depth=-1,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.8,\n",
    "                    class_weight='balanced',\n",
    "                    objective='binary',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(f'XGBoost available: {xgb_available}')\n",
    "print(f'LightGBM available: {lgbm_available}')\n",
    "\n",
    "sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "feasibility_rows = []\n",
    "\n",
    "for model_name, model in candidate_models.items():\n",
    "    fit_kwargs = {}\n",
    "    if model_name in ['GradientBoosting_weighted', 'HistGradientBoosting']:\n",
    "        fit_kwargs = {'model__sample_weight': sample_weight}\n",
    "\n",
    "    model.fit(X_train, y_train, **fit_kwargs)\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, val_proba)\n",
    "\n",
    "    pr_df = pd.DataFrame({\n",
    "        'precision': precisions[:-1],\n",
    "        'recall': recalls[:-1],\n",
    "        'threshold': thresholds,\n",
    "    })\n",
    "\n",
    "    meets_recall = pr_df[pr_df['recall'] >= TARGET_RECALL]\n",
    "    if len(meets_recall) > 0:\n",
    "        best_prec_at_target_recall = meets_recall['precision'].max()\n",
    "    else:\n",
    "        best_prec_at_target_recall = 0.0\n",
    "\n",
    "    meets_precision = pr_df[pr_df['precision'] >= TARGET_PRECISION]\n",
    "    if len(meets_precision) > 0:\n",
    "        best_recall_at_target_precision = meets_precision['recall'].max()\n",
    "    else:\n",
    "        best_recall_at_target_precision = 0.0\n",
    "\n",
    "    both_target = pr_df[(pr_df['precision'] >= TARGET_PRECISION) & (pr_df['recall'] >= TARGET_RECALL)]\n",
    "    if len(both_target) > 0:\n",
    "        best_both = both_target.sort_values(by=['recall', 'precision'], ascending=False).iloc[0]\n",
    "        feasible = True\n",
    "        chosen_threshold = float(best_both['threshold'])\n",
    "        chosen_precision = float(best_both['precision'])\n",
    "        chosen_recall = float(best_both['recall'])\n",
    "    else:\n",
    "        feasible = False\n",
    "        chosen_threshold = np.nan\n",
    "        chosen_precision = np.nan\n",
    "        chosen_recall = np.nan\n",
    "\n",
    "    feasibility_rows.append(\n",
    "        {\n",
    "            'model': model_name,\n",
    "            'feasible_precision>=0.80_recall>=0.90': feasible,\n",
    "            'best_precision_when_recall>=0.90': best_prec_at_target_recall,\n",
    "            'best_recall_when_precision>=0.80': best_recall_at_target_precision,\n",
    "            'threshold_if_both_feasible': chosen_threshold,\n",
    "            'precision_if_both_feasible': chosen_precision,\n",
    "            'recall_if_both_feasible': chosen_recall,\n",
    "        }\n",
    "    )\n",
    "\n",
    "feasibility_df = pd.DataFrame(feasibility_rows).sort_values(\n",
    "    by=['feasible_precision>=0.80_recall>=0.90', 'best_precision_when_recall>=0.90', 'best_recall_when_precision>=0.80'],\n",
    "    ascending=[False, False, False],\n",
    ")\n",
    "\n",
    "print('Can we hit Precision >= 0.80 and Recall >= 0.90 on validation?')\n",
    "feasibility_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1067d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516e1fef",
   "metadata": {},
   "source": [
    "### 7) Final comparison table (your main model vs alternatives)\n",
    "\n",
    "Main model chosen:\n",
    "- **GradientBoostingClassifier**\n",
    "- threshold = `0.20`\n",
    "- `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`, `min_samples_leaf=1`\n",
    "\n",
    "Below, we compare this setup against Logistic Regression, Random Forest, and XGBoost using reasonable baseline parameters.\n",
    "For fair comparison, we use the **same threshold (0.20)** for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393da912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "THRESHOLD_COMPARE = 0.20\n",
    "RECALL_WEIGHT = 0.8\n",
    "PRECISION_WEIGHT = 0.2\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_ok = True\n",
    "except ImportError:\n",
    "    xgb_ok = False\n",
    "\n",
    "neg_count = int((y_train == 0).sum())\n",
    "pos_count = int((y_train == 1).sum())\n",
    "scale_pos_weight = neg_count / max(pos_count, 1)\n",
    "\n",
    "comparison_models = {\n",
    "    'GradientBoosting': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                GradientBoostingClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=3,\n",
    "                    min_samples_leaf=1,\n",
    "                    random_state=42,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    'RandomForest': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=400,\n",
    "                    max_depth=10,\n",
    "                    min_samples_leaf=3,\n",
    "                    class_weight='balanced',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    'LogisticRegression': Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                LogisticRegression(\n",
    "                    class_weight='balanced',\n",
    "                    solver='liblinear',\n",
    "                    max_iter=5000,\n",
    "                    random_state=42,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "if xgb_ok:\n",
    "    comparison_models['XGBoost'] = Pipeline(\n",
    "        [\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            (\n",
    "                'model',\n",
    "                XGBClassifier(\n",
    "                    n_estimators=400,\n",
    "                    learning_rate=0.05,\n",
    "                    max_depth=4,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.8,\n",
    "                    reg_lambda=2.0,\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    objective='binary:logistic',\n",
    "                    eval_metric='logloss',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    print('XGBoost is not installed in this kernel, so it will be skipped.')\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average='binary',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    score_08r_02p = RECALL_WEIGHT * r + PRECISION_WEIGHT * p\n",
    "    return p, r, f1, score_08r_02p\n",
    "\n",
    "\n",
    "comparison_rows = []\n",
    "train_sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "for model_name, model in comparison_models.items():\n",
    "    fit_kwargs = {}\n",
    "    if model_name == 'GradientBoosting':\n",
    "        fit_kwargs = {'model__sample_weight': train_sample_weight}\n",
    "\n",
    "    model.fit(X_train, y_train, **fit_kwargs)\n",
    "\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    val_pred = (val_proba >= THRESHOLD_COMPARE).astype(int)\n",
    "    test_pred = (test_proba >= THRESHOLD_COMPARE).astype(int)\n",
    "\n",
    "    val_p, val_r, val_f1, val_score = get_metrics(y_val, val_pred)\n",
    "    test_p, test_r, test_f1, test_score = get_metrics(y_test, test_pred)\n",
    "\n",
    "    comparison_rows.append(\n",
    "        {\n",
    "            'model': model_name,\n",
    "            'threshold': THRESHOLD_COMPARE,\n",
    "            'val_precision': val_p,\n",
    "            'val_recall': val_r,\n",
    "            'val_f1': val_f1,\n",
    "            'val_0.8R+0.2P': val_score,\n",
    "            'test_precision': test_p,\n",
    "            'test_recall': test_r,\n",
    "            'test_f1': test_f1,\n",
    "            'test_0.8R+0.2P': test_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_rows).sort_values(\n",
    "    by=['test_0.8R+0.2P', 'test_recall', 'test_precision'],\n",
    "    ascending=False,\n",
    ")\n",
    "\n",
    "# Requested formatting: show 0.8R+0.2P columns with 4 decimal places\n",
    "comparison_df['val_0.8R+0.2P'] = comparison_df['val_0.8R+0.2P'].round(4)\n",
    "comparison_df['test_0.8R+0.2P'] = comparison_df['test_0.8R+0.2P'].round(4)\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3498346",
   "metadata": {},
   "source": [
    "### 8) Export comparison table as image for GitHub\n",
    "\n",
    "This cell converts `comparison_df` into a styled PNG image and saves it in the project root.\n",
    "The main model row (`GradientBoosting`) is highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image: c:\\Users\\acer\\Desktop\\programming\\projects\\Survival\\comparison_table_github.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "if 'comparison_df' not in globals():\n",
    "    raise ValueError('comparison_df not found. Run the comparison table cell first.')\n",
    "\n",
    "export_df = comparison_df.copy()\n",
    "\n",
    "numeric_cols = [\n",
    "    'threshold',\n",
    "    'val_precision',\n",
    "    'val_recall',\n",
    "    'val_f1',\n",
    "    'test_precision',\n",
    "    'test_recall',\n",
    "    'test_f1',\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    if col in export_df.columns:\n",
    "        export_df[col] = export_df[col].round(3)\n",
    "\n",
    "# Requested formatting: 0.8R+0.2P columns with 4 decimals\n",
    "score_cols = ['val_0.8R+0.2P', 'test_0.8R+0.2P']\n",
    "for col in score_cols:\n",
    "    if col in export_df.columns:\n",
    "        export_df[col] = export_df[col].round(4)\n",
    "\n",
    "pretty_df = export_df.rename(\n",
    "    columns={\n",
    "        'model': 'Model',\n",
    "        'threshold': 'Threshold',\n",
    "        'val_precision': 'Val Precision',\n",
    "        'val_recall': 'Val Recall',\n",
    "        'val_f1': 'Val F1',\n",
    "        'val_0.8R+0.2P': 'Val (0.8R+0.2P)',\n",
    "        'test_precision': 'Test Precision',\n",
    "        'test_recall': 'Test Recall',\n",
    "        'test_f1': 'Test F1',\n",
    "        'test_0.8R+0.2P': 'Test (0.8R+0.2P)',\n",
    "    }\n",
    ")\n",
    "\n",
    "rows, cols = pretty_df.shape\n",
    "fig_width = min(22, max(14, cols * 1.8))\n",
    "fig_height = max(2.5, 1.4 + rows * 0.55)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=pretty_df.values,\n",
    "    colLabels=pretty_df.columns,\n",
    "    loc='center',\n",
    "    cellLoc='center',\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.45)\n",
    "\n",
    "header_color = '#1f4e79'\n",
    "header_text_color = 'white'\n",
    "main_row_color = '#e8f5e9'\n",
    "alt_row_color = '#f7f9fc'\n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('#d0d7de')\n",
    "    if row == 0:\n",
    "        cell.set_facecolor(header_color)\n",
    "        cell.get_text().set_color(header_text_color)\n",
    "        cell.get_text().set_weight('bold')\n",
    "    else:\n",
    "        model_name = str(pretty_df.iloc[row - 1, 0])\n",
    "        if model_name == 'GradientBoosting':\n",
    "            cell.set_facecolor(main_row_color)\n",
    "            if col == 0:\n",
    "                cell.get_text().set_weight('bold')\n",
    "        elif row % 2 == 0:\n",
    "            cell.set_facecolor(alt_row_color)\n",
    "\n",
    "plt.title('Model Comparison Table', fontsize=15, weight='bold', pad=18)\n",
    "\n",
    "output_path = Path.cwd() / 'comparison_table_github.png'\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Saved image: {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea379ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
